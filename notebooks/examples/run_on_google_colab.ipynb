{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Andrei-Aksionov/nanoGPTplus/blob/feature/google_colab_notebook/notebooks/examples/run_on_google_colab.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7cBYZpxq4hlH",
    "outputId": "863850c2-beb4-4cc8-8824-ef0143ec9002"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.16\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNmuWm3UAzUX"
   },
   "source": [
    "How to change runtime type [link](https://www.tutorialspoint.com/google_colab/google_colab_using_free_gpu.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yOMt2BC0AWC5",
    "outputId": "4296c136-e73f-4cac-d159-827f8525ed03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 17 14:44:53 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   56C    P0    28W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-kqQF--QD5Y",
    "outputId": "b1ee9375-3b72-4efe-db0d-5bdd409021bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'nanoGPTplus'...\n",
      "remote: Enumerating objects: 280, done.\u001b[K\n",
      "remote: Counting objects: 100% (162/162), done.\u001b[K\n",
      "remote: Compressing objects: 100% (109/109), done.\u001b[K\n",
      "remote: Total 280 (delta 83), reused 64 (delta 47), pack-reused 118\u001b[K\n",
      "Receiving objects: 100% (280/280), 659.10 KiB | 6.34 MiB/s, done.\n",
      "Resolving deltas: 100% (117/117), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Andrei-Aksionov/nanoGPTplus.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tTTDQDUe1buZ",
    "outputId": "df1ec4d8-e054-4587-91b8-917570eeb59d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nanoGPTplus\n",
      "LICENSE    poetry.lock\t   README.md   src\n",
      "notebooks  pyproject.toml  references  tests\n"
     ]
    }
   ],
   "source": [
    "%cd nanoGPTplus/\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-_adTWI188f",
    "outputId": "15bfd6f2-5c89-47c4-ea47-d906bf01cc61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting virtualenv\n",
      "  Downloading virtualenv-20.21.0-py3-none-any.whl (8.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.9/dist-packages (from virtualenv) (3.1.1)\n",
      "Collecting distlib<1,>=0.3.6\n",
      "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock<4,>=3.4.1 in /usr/local/lib/python3.9/dist-packages (from virtualenv) (3.9.1)\n",
      "Installing collected packages: distlib, virtualenv\n",
      "Successfully installed distlib-0.3.6 virtualenv-20.21.0\n",
      "created virtual environment CPython3.9.16.final.0-64 in 1531ms\n",
      "  creator CPython3Posix(dest=/content/nanoGPTplus/venv, clear=False, no_vcs_ignore=False, global=False)\n",
      "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
      "    added seed packages: pip==23.0.1, setuptools==67.4.0, wheel==0.38.4\n",
      "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
     ]
    }
   ],
   "source": [
    "!pip install virtualenv\n",
    "!virtualenv venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t7_cBPZwLHag",
    "outputId": "1fc9b015-ba68-4241-b944-2a2d696fe565"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/nanoGPTplus/venv/bin:/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PATH\"] = f\"{os.getcwd()}/venv/bin:{os.environ['PATH']}\"\n",
    "!echo $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rINXOd4lAMLo"
   },
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EssNhOKdBgLS",
    "outputId": "06e8657f-4139-4253-f6ca-1a3c1b8117e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Obtaining file:///content/nanoGPTplus\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting numpy<1.25.0,>=1.24.1\n",
      "  Downloading numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ipykernel<6.22.0,>=6.21.1\n",
      "  Downloading ipykernel-6.21.3-py3-none-any.whl (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas<1.6.0,>=1.5.2\n",
      "  Downloading pandas-1.5.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tiktoken<0.4.0,>=0.3.1\n",
      "  Downloading tiktoken-0.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting loguru<0.7.0,>=0.6.0\n",
      "  Downloading loguru-0.6.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm<4.65.0,>=4.64.1\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting omegaconf<2.4.0,>=2.3.0\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch<1.14.0,>=1.13.0\n",
      "  Downloading torch-1.13.1-cp39-cp39-manylinux1_x86_64.whl (887.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers<4.27.0,>=4.26.1\n",
      "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib<3.7.0,>=3.6.3\n",
      "  Downloading matplotlib-3.6.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests<2.29.0,>=2.28.1\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.13.0,>=2.12.0\n",
      "  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nest-asyncio\n",
      "  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
      "Collecting debugpy>=1.6.5\n",
      "  Downloading debugpy-1.6.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting packaging\n",
      "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting comm>=0.1.1\n",
      "  Downloading comm-0.1.2-py3-none-any.whl (6.5 kB)\n",
      "Collecting pyzmq>=20\n",
      "  Downloading pyzmq-25.0.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tornado>=6.1\n",
      "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.0/424.0 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib-inline>=0.1\n",
      "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
      "Collecting jupyter-client>=6.1.12\n",
      "  Downloading jupyter_client-8.0.3-py3-none-any.whl (102 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ipython>=7.23.1\n",
      "  Downloading ipython-8.11.0-py3-none-any.whl (793 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.3/793.3 kB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting traitlets>=5.4.0\n",
      "  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting psutil\n",
      "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jupyter-core!=5.0.*,>=4.12\n",
      "  Downloading jupyter_core-5.3.0-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing>=2.2.1\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting python-dateutil>=2.7\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.39.2-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.7/299.7 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting antlr4-python3-runtime==4.9.*\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting PyYAML>=5.1.0\n",
      "  Downloading PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.8/661.8 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m499.4/499.4 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.9/140.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.51.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in ./venv/lib/python3.9/site-packages (from tensorboard<2.13.0,>=2.12.0->nanogptplus==1.0.0) (67.4.0)\n",
      "Requirement already satisfied: wheel>=0.26 in ./venv/lib/python3.9/site-packages (from tensorboard<2.13.0,>=2.12.0->nanogptplus==1.0.0) (0.38.4)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf>=3.19.6\n",
      "  Downloading protobuf-4.22.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex>=2022.1.18\n",
      "  Downloading regex-2022.10.31-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.0/770.0 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.13.2-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.10.0-py3-none-any.whl (9.9 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting six>=1.9.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting pexpect>4.3\n",
      "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting decorator\n",
      "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting pickleshare\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Collecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30\n",
      "  Downloading prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting stack-data\n",
      "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
      "Collecting pygments>=2.4.0\n",
      "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jedi>=0.16\n",
      "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting backcall\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting importlib-metadata>=4.8.3\n",
      "  Downloading importlib_metadata-6.0.0-py3-none-any.whl (21 kB)\n",
      "Collecting platformdirs>=2.5\n",
      "  Downloading platformdirs-3.1.1-py3-none-any.whl (14 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Collecting parso<0.9.0,>=0.8.0\n",
      "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ptyprocess>=0.5\n",
      "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting wcwidth\n",
      "  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting executing>=1.2.0\n",
      "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting pure-eval\n",
      "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "Collecting asttokens>=2.1.0\n",
      "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
      "Building wheels for collected packages: nanogptplus, antlr4-python3-runtime\n",
      "  Building editable for nanogptplus (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for nanogptplus: filename=nanogptplus-1.0.0-py3-none-any.whl size=5949 sha256=1f728579ec7f4c0fecc5b476bc193a99bbb23bb1c7215ca8313cb1f460c6de68\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-f73ayb43/wheels/c8/aa/79/5cfb1a77e2db6d7df0ba23182e9b41d856973763132ff52909\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144573 sha256=b7cf31a99d29308eeb5ec3d0f6fee2f4e01ffc14a1e1625ced1868b77f37a998\n",
      "  Stored in directory: /root/.cache/pip/wheels/23/cf/80/f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n",
      "Successfully built nanogptplus antlr4-python3-runtime\n",
      "Installing collected packages: wcwidth, tokenizers, tensorboard-plugin-wit, pytz, pyasn1, pure-eval, ptyprocess, pickleshare, executing, backcall, antlr4-python3-runtime, zipp, urllib3, typing-extensions, traitlets, tqdm, tornado, tensorboard-data-server, six, rsa, regex, pyzmq, PyYAML, pyparsing, pygments, pyasn1-modules, psutil, protobuf, prompt-toolkit, platformdirs, pillow, pexpect, parso, packaging, oauthlib, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, numpy, nest-asyncio, MarkupSafe, loguru, kiwisolver, idna, grpcio, fonttools, filelock, decorator, debugpy, cycler, charset-normalizer, certifi, cachetools, absl-py, werkzeug, requests, python-dateutil, omegaconf, nvidia-cudnn-cu11, matplotlib-inline, jupyter-core, jedi, importlib-metadata, google-auth, contourpy, comm, asttokens, torch, tiktoken, stack-data, requests-oauthlib, pandas, matplotlib, markdown, jupyter-client, huggingface-hub, transformers, ipython, google-auth-oauthlib, tensorboard, ipykernel, nanogptplus\n",
      "Successfully installed MarkupSafe-2.1.2 PyYAML-6.0 absl-py-1.4.0 antlr4-python3-runtime-4.9.3 asttokens-2.2.1 backcall-0.2.0 cachetools-5.3.0 certifi-2022.12.7 charset-normalizer-3.1.0 comm-0.1.2 contourpy-1.0.7 cycler-0.11.0 debugpy-1.6.6 decorator-5.1.1 executing-1.2.0 filelock-3.10.0 fonttools-4.39.2 google-auth-2.16.2 google-auth-oauthlib-0.4.6 grpcio-1.51.3 huggingface-hub-0.13.2 idna-3.4 importlib-metadata-6.0.0 ipykernel-6.21.3 ipython-8.11.0 jedi-0.18.2 jupyter-client-8.0.3 jupyter-core-5.3.0 kiwisolver-1.4.4 loguru-0.6.0 markdown-3.4.1 matplotlib-3.6.3 matplotlib-inline-0.1.6 nanogptplus-1.0.0 nest-asyncio-1.5.6 numpy-1.24.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 oauthlib-3.2.2 omegaconf-2.3.0 packaging-23.0 pandas-1.5.3 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 pillow-9.4.0 platformdirs-3.1.1 prompt-toolkit-3.0.38 protobuf-4.22.1 psutil-5.9.4 ptyprocess-0.7.0 pure-eval-0.2.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 pygments-2.14.0 pyparsing-3.0.9 python-dateutil-2.8.2 pytz-2022.7.1 pyzmq-25.0.1 regex-2022.10.31 requests-2.28.2 requests-oauthlib-1.3.1 rsa-4.9 six-1.16.0 stack-data-0.6.2 tensorboard-2.12.0 tensorboard-data-server-0.7.0 tensorboard-plugin-wit-1.8.1 tiktoken-0.3.2 tokenizers-0.13.2 torch-1.13.1 tornado-6.2 tqdm-4.64.1 traitlets-5.9.0 transformers-4.26.1 typing-extensions-4.5.0 urllib3-1.26.15 wcwidth-0.2.6 werkzeug-2.2.3 zipp-3.15.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "certifi",
         "cycler",
         "dateutil",
         "debugpy",
         "google",
         "kiwisolver",
         "pexpect",
         "pickleshare",
         "tornado",
         "wcwidth",
         "zipp"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dgFz_bvGCzrs",
    "outputId": "05da6cf1-fd5a-4403-9c3e-bc0bccb81f9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-03-17 14:38:59.773\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.data.downloader\u001b[0m:\u001b[36mdownload\u001b[0m:\u001b[36m34\u001b[0m - \u001b[34m\u001b[1mDownloading https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt into /content/nanoGPTplus/data/raw/tiny_shakespeare\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:00.123\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.data.downloader\u001b[0m:\u001b[36mdownload\u001b[0m:\u001b[36m44\u001b[0m - \u001b[34m\u001b[1mDownloading is finished\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python src/data/scripts/download_tiny_shakespeare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqPjJzzCC9VZ",
    "outputId": "00c5e41b-6a34-45d0-9ec5-9d6c6526965e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-03-17 14:39:02.634\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m60\u001b[0m - \u001b[34m\u001b[1mRandom seed is fixed for training.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:02.635\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mLoading the data...\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:02.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mData is loaded.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:02.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mStarting tokenizing...\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:02.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mTokenizing is done.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:02.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m79\u001b[0m - \u001b[1mSaving tokenizer...\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:02.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mTokenizer is saved.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:02.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mPreparing data loaders...\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:02.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mData loaders are prepared.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:02.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mStaring training...\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:02.894\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mLR warmup iters: 0\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:02.894\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m137\u001b[0m - \u001b[34m\u001b[1mLR decay iters: 3138\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:05.939\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.model.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m122\u001b[0m - \u001b[34m\u001b[1mTraining on 'cuda' device\u001b[0m\n",
      "=============== Epoch: 0 ===============\n",
      "train: 100% 3138/3138 [00:08<00:00, 372.78it/s, loss=2.51]\n",
      "eval: 100% 349/349 [00:00<00:00, 349.49it/s, loss=2.89]\n",
      "Eval averaged loss: 2.8838\n",
      "\u001b[32m2023-03-17 14:39:15.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mCurrent eval loss is `2.8838` which is smaller than current best loss of `inf`; saving the model...\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:15.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mBest model is saved.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:15.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mTraining is finished\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python src/model/train.py bigram --size large --dataset-fraction 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lCYLOa8VDmeR",
    "outputId": "2d6ee2c9-a0bf-4f01-a826-95d47be99944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-03-17 14:39:17.703\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_new_tokens\u001b[0m:\u001b[36m69\u001b[0m - \u001b[34m\u001b[1mRandom seed is fixed for token generation.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:20.345\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_new_tokens\u001b[0m:\u001b[36m104\u001b[0m - \u001b[34m\u001b[1mGenerating tokens on 'cuda' device\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:20.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_new_tokens\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mNew generated tokens:  d\n",
      "Ou as; nte ti'd te ondur modithand he, preckn,\n",
      "\n",
      "Henthim, acind\n",
      "\n",
      "Mapinisercald s, oreanotsthelu.\n",
      "GI\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:20.390\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_new_tokens\u001b[0m:\u001b[36m121\u001b[0m - \u001b[34m\u001b[1mToken generation took: 0.0453 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python src/model/generate.py bigram --size large --max-new-tokens 100 --fix-seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZT4Q1reoEW8r",
    "outputId": "1a7cecd5-cce9-480b-df22-8bb1b528d5e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-03-17 14:39:22.727\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m60\u001b[0m - \u001b[34m\u001b[1mRandom seed is fixed for training.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:22.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mLoading the data...\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:22.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mData is loaded.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:22.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m73\u001b[0m - \u001b[1mStarting tokenizing...\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:22.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mTokenizing is done.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:22.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m79\u001b[0m - \u001b[1mSaving tokenizer...\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:22.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m81\u001b[0m - \u001b[1mTokenizer is saved.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:22.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mPreparing data loaders...\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:22.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mData loaders are prepared.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:22.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m106\u001b[0m - \u001b[1mStaring training...\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:22.995\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.model.gpt_language_model.gpt\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m114\u001b[0m - \u001b[34m\u001b[1mGPT language model is created with number of parameters: 0.80 million\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:22.996\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m131\u001b[0m - \u001b[34m\u001b[1mLR warmup iters: 83\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:22.996\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m137\u001b[0m - \u001b[34m\u001b[1mLR decay iters: 795\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:25.212\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.model.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m122\u001b[0m - \u001b[34m\u001b[1mTraining on 'cuda' device\u001b[0m\n",
      "=============== Epoch: 0 ===============\n",
      "train: 100% 837/837 [00:13<00:00, 64.26it/s, loss=2.34]\n",
      "eval: 100% 93/93 [00:00<00:00, 106.60it/s, loss=2.71]\n",
      "Eval averaged loss: 2.7081\n",
      "\u001b[32m2023-03-17 14:39:39.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m151\u001b[0m - \u001b[1mCurrent eval loss is `2.7081` which is smaller than current best loss of `inf`; saving the model...\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:39.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.model.trainer\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mBest model is saved.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:39.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m156\u001b[0m - \u001b[1mTraining is finished\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !python src/model/train.py --model gpt --size medium --dataset-fraction 0.1\n",
    "!python src/model/train.py gpt --size small --dataset-fraction 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGW67vbyMamT",
    "outputId": "7bd24e83-a6bd-482d-fb3a-60984bcd5dd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-03-17 14:39:41.508\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_new_tokens\u001b[0m:\u001b[36m69\u001b[0m - \u001b[34m\u001b[1mRandom seed is fixed for token generation.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:42.148\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.model.gpt_language_model.gpt\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m114\u001b[0m - \u001b[34m\u001b[1mGPT language model is created with number of parameters: 0.80 million\u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:44.241\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_new_tokens\u001b[0m:\u001b[36m104\u001b[0m - \u001b[34m\u001b[1mGenerating tokens on 'cuda' device\u001b[0m\n",
      "100% 1000/1000 [00:03<00:00, 287.75it/s]\n",
      "\u001b[32m2023-03-17 14:39:47.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_new_tokens\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mNew generated tokens:  decin: afnte thitnse ot uarmd therid he bubeckn,\n",
      "Ofe the go--And thapveis bur I sukorgheltsAne us thandy;\n",
      "Ade eveRd thak mangENof whas\n",
      "bshind mean theur thateghs mormac, nsely. Fou d irin----wunoreicensends ce Firstoes nveee? qmatores\n",
      "\n",
      "\n",
      "? CithyoreciKaSen:\n",
      "\n",
      "TBusins-; munius erve stOrend bunn y anestay, y at' blire ry, yo ph-ARpeleie t\n",
      "\n",
      "Thosts areellungh ofbrsety athers at, ban te sheire akns tho'vew a amnf dorsvos nde:\n",
      "ishe matasy Ve ou magrerst, atsts, titory!\n",
      "\n",
      "FrsthaiknB'seUCinks, g duthinting chise. Whed veay ubd rematont s:\n",
      "Daticas sy hapy dburi,\n",
      "Stitirss o;UlYnd ke care. Your vesS youves,\n",
      "Hn tinat tres ware bo avit; kis,\n",
      "Whingh thit, arase to tnst uorseche es lei; muswich?\n",
      "Ye's may actrSte icongas, may beroriuply, chanlFoucy; m ritWhe you\n",
      "\n",
      "Themels we anfleids dit thiss ooom\n",
      "llctste peierd, myscensoucong ay,rinu, eromstint. wh And: Hathe cesed none har yous.\n",
      "-bunelve s, Whathat\n",
      "Alnd, Thof eacou'gr the, pelit baty rcchary aCich's?!\n",
      "\n",
      "Tfime Con:\n",
      "MENIqXou,\n",
      "MIUS:\n",
      "-Buse al:\n",
      "MAncou: y cou \u001b[0m\n",
      "\u001b[32m2023-03-17 14:39:47.720\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_new_tokens\u001b[0m:\u001b[36m121\u001b[0m - \u001b[34m\u001b[1mToken generation took: 3.4787 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !python src/model/generate.py --model gpt --size medium --max-new-tokens 1000\n",
    "!python src/model/generate.py gpt --size small --max-new-tokens 1000 --fix-seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bl-igDB8_EOP"
   },
   "source": [
    "## Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "biUnerKq_Bb2",
    "outputId": "9e0aa2c7-c088-442c-e0ae-b3be5cdcead7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-03-17 14:43:16.288\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_new_tokens\u001b[0m:\u001b[36m69\u001b[0m - \u001b[34m\u001b[1mRandom seed is fixed for token generation.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:43:17.473\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.model.gpt_language_model.gpt\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m340\u001b[0m - \u001b[34m\u001b[1mCreating GPT model with parameters: {'vocab_size': 50257, 'embeddings_size': 768, 'context_size': 1024, 'num_layers': 12, 'num_heads': 12, 'head_size': None, 'feed_forward_scaling': 4, 'bias': True, 'dropout': 0.1}\u001b[0m\n",
      "\u001b[32m2023-03-17 14:43:21.217\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.model.gpt_language_model.gpt\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m114\u001b[0m - \u001b[34m\u001b[1mGPT language model is created with number of parameters: 123.65 million\u001b[0m\n",
      "\u001b[32m2023-03-17 14:43:21.219\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.model.gpt_language_model.gpt\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m348\u001b[0m - \u001b[34m\u001b[1mLoading pretrained Huggingface model of size 'gpt2' ...\u001b[0m\n",
      "\u001b[32m2023-03-17 14:43:24.054\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.model.gpt_language_model.gpt\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m350\u001b[0m - \u001b[34m\u001b[1mHuggingface model is loaded.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:43:24.056\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.model.gpt_language_model.gpt\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m387\u001b[0m - \u001b[34m\u001b[1mStarting copying weights from pretrained Huggingface model into our implementation ...\u001b[0m\n",
      "\u001b[32m2023-03-17 14:43:24.372\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.model.gpt_language_model.gpt\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m401\u001b[0m - \u001b[34m\u001b[1mWeights are copied.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:43:26.599\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_new_tokens\u001b[0m:\u001b[36m104\u001b[0m - \u001b[34m\u001b[1mGenerating tokens on 'cuda' device\u001b[0m\n",
      "100% 1000/1000 [00:42<00:00, 23.38it/s]\n",
      "\u001b[32m2023-03-17 14:44:09.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_new_tokens\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mNew generated tokens: My name is giovanni giorgio but everybody calls me ?\" the station reporter asked as the Chief Served Rider stopped his footsteps and whispered something to him.\n",
      "\n",
      "\"Ask all her colleagues, Dorica,\" the mere messenger said, underconfidence in his voice. \"Now call Mr. Corrado close and ask about her.\" All of the charges of corruption were dismissed as a matter of course and Dorica at that moment suddenly realized that in many respects this was not true and she began to swoon.\n",
      "\n",
      "\"Missus Corrado…\" the Chief Served Rider thrust himself forward as quickly as he could from the rubble floor and silently began packing up his belongings. It didn't take long for gormayo to realize that she couldn't touch Column Chief Corrado back to his flat anymore and the territory he had captured had been completely annihilated. All he could do was turn himself in and leave.\n",
      "\n",
      "He gathered there for some sympathetic finery and nothing really happened but Corrado had returned to his desk within minutes and he almost pointed his smartphone right at Corrado and he immediately started typing Also emailing him all about how Christine had let off a bad vibe and did somebody summon him to ONE OF THE DEAD MEAN RATS to see if they couldn't find the lemmings in Rom/Giovanni's mansion that, if they could, he would take them home with him at his command. He stayed in his desk for awhile of which… after a few moments and all this he figured that Ronald might make it but the truth was he didn't know what to do and this goes over well with the morons. Somehow he felt just as much of book management as guro was, the librarian came running through the back. She called for the bottle he had thrown from under her desk in seconds and asked if there was anything he could drop; she spoke as if the entire series of numbers that followed her were just a hailstorm of people implanted in her nutsher and faded away.\n",
      "\n",
      "There came an awkward pause as she said bluntly, \"have you promised for awhile Danielle that I can just come in the house and help?\" And as soon as he finally arrived, the door to his apartment opened and\n",
      "\n",
      "din said with a bloody smile, all of a sudden she instantly went bastard and the building exploded into a fireball of flesh and gore.\n",
      "\n",
      "Bbranded of ending:'02 GF04AdGK4D81G5eP8C5rde459neOps4cB8Dc568392AL\n",
      "\n",
      "2IKFK6vycapkIlV216uWRDe3tHfck_1GaoikDOMrO<|endoftext|>Found my wish suddenly amidst a torrent of sudden, alarming updates Monday morning during the Wachowski School, while school coffee was drying. You have at least noticed me, right now. I'm picnicking with the Caddy full of zombies and goddamn weird face portraits over high school home-trains. This first freak flood has brought this wonderful animal down sharply, murdering many folks's heads as I run, \"outta here…ESE HANG ON CHINA, KARL!!! HER MILF NEEDS TO BE STRONG, KU ON!\" I'm getting stuck at the pedal bullypinder speed, which (after laying around wondering if this guy was weird or if there could be a universe of him) looks like a reaction I should set off.\n",
      "\n",
      "\n",
      "I burst through that speed ritual exit through the back door.\n",
      "\n",
      "\n",
      "Jesse, that obnoxious child Verisign, must still be writhing under the skidmark drink, stuffing a thumb up his pannier like a CHILD. She and Danielle have arrived to alakazam, and indeed this city is in ruins...\n",
      "\n",
      "Can't wait to make that start over from above that second vigor trial thing…\n",
      "\n",
      "\n",
      "The Jett\n",
      "\n",
      "Fuck… he crashed the car and I changed to a bomb machine. Hopefully Torrence Post will be there in a couple of hours to spur me off.\n",
      "\n",
      "Dave, that dude has Einstein inside him… Also, I fully realize that there might be some rope scruples over his restroom every night, as well as the bloody cow in his ass, so he needs some toilet paper at least on hot months ofrdum…. SO late afternoon EST to be getting ready for test.\n",
      "\n",
      "Jake, stay away.\n",
      "\n",
      "…And Dave. Do men exist, after all? Actually, think about it– if it's sports at all. It's the sports that happen in competitive basketball and rugby every day, and…\"Fun\".\n",
      "\n",
      "Done.\n",
      "\n",
      "I'll go in the scream factory:\n",
      "\n",
      "…and night just as a free Jig?\n",
      "\n",
      "He'll must be counting down.\n",
      "\n",
      "Bernie\n",
      "\n",
      "Gary, I have school kicked off this morning, and I am\u001b[0m\n",
      "\u001b[32m2023-03-17 14:44:09.369\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_new_tokens\u001b[0m:\u001b[36m121\u001b[0m - \u001b[34m\u001b[1mToken generation took: 42.7695 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python src/model/generate.py gpt --gpt2-config gpt2 --max-new-tokens 1000 --fix-seed --continue-tokens \"My name is Giovanni Giorgio but everybody calls me \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SNmvA2sS-PaP",
    "outputId": "558a836d-a9e5-42b2-cc64-4ab75746593c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-03-17 14:41:54.801\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_new_tokens\u001b[0m:\u001b[36m69\u001b[0m - \u001b[34m\u001b[1mRandom seed is fixed for token generation.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:41:56.339\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.model.gpt_language_model.gpt\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m340\u001b[0m - \u001b[34m\u001b[1mCreating GPT model with parameters: {'vocab_size': 50257, 'embeddings_size': 768, 'context_size': 1024, 'num_layers': 12, 'num_heads': 12, 'head_size': None, 'feed_forward_scaling': 4, 'bias': True, 'dropout': 0.1}\u001b[0m\n",
      "\u001b[32m2023-03-17 14:41:59.132\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.model.gpt_language_model.gpt\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m114\u001b[0m - \u001b[34m\u001b[1mGPT language model is created with number of parameters: 123.65 million\u001b[0m\n",
      "\u001b[32m2023-03-17 14:41:59.133\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.model.gpt_language_model.gpt\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m348\u001b[0m - \u001b[34m\u001b[1mLoading pretrained Huggingface model of size 'gpt2' ...\u001b[0m\n",
      "\u001b[32m2023-03-17 14:42:01.072\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.model.gpt_language_model.gpt\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m350\u001b[0m - \u001b[34m\u001b[1mHuggingface model is loaded.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:42:01.073\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.model.gpt_language_model.gpt\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m387\u001b[0m - \u001b[34m\u001b[1mStarting copying weights from pretrained Huggingface model into our implementation ...\u001b[0m\n",
      "\u001b[32m2023-03-17 14:42:01.331\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.model.gpt_language_model.gpt\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m401\u001b[0m - \u001b[34m\u001b[1mWeights are copied.\u001b[0m\n",
      "\u001b[32m2023-03-17 14:42:03.047\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_new_tokens\u001b[0m:\u001b[36m104\u001b[0m - \u001b[34m\u001b[1mGenerating tokens on 'cuda' device\u001b[0m\n",
      "100% 1000/1000 [00:10<00:00, 99.64it/s]\n",
      "\u001b[32m2023-03-17 14:42:13.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_new_tokens\u001b[0m:\u001b[36m120\u001b[0m - \u001b[1mNew generated tokens: My name is giovanni giorgio but everybody calls me ?\" the station reporter asked as the Chief Served Rider stopped his footsteps and whispered something to him.\n",
      "\n",
      "\"Ask all her colleagues, Dorica,\" the mere messenger said, underconfidence in his voice. \"Now call Mr. Corrado close and ask about her.\" All of the charges of corruption were dismissed as a matter of course and Dorica at that moment suddenly realized that in many respects this was not true and she began to swoon.\n",
      "\n",
      "\"Missus Corrado…\" the Chief Served Rider thrust himself forward as quickly as he could from the rubble floor and silently began packing up his belongings. It didn't take long for gormayo to realize that she couldn't touch Column Chief Corrado back to his flat anymore and the territory he had captured had been completely annihilated. All he could do was turn himself in and leave.\n",
      "\n",
      "He gathered there for some sympathetic finery and nothing really happened but Corrado had returned to his desk within minutes and he almost pointed his smartphone right at Corrado and he immediately started typing Also emailing him all about how Christine had let off a bad vibe and did somebody summon him to ONE OF THE DEAD MEAN RATS to see if they couldn't find the lemmings in Rom/Giovanni's mansion that, if they could, he would take them home with him at his command. He stayed in his desk for awhile of which… after a few moments and all this he figured that Ronald might make it but the truth was he didn't know what to do and this goes over well with the morons. Somehow he felt just as much of book management as guro was, the librarian came running through the back. She called for the bottle he had thrown from under her desk in seconds and asked if there was anything he could drop; she spoke as if the entire series of numbers that followed her were just a hailstorm of people implanted in her nutsher and faded away.\n",
      "\n",
      "There came an awkward pause as she said bluntly, \"have you promised for awhile Danielle that I can just come in the house and help?\" And as soon as he finally arrived, the door to his apartment opened and\n",
      "\n",
      "din said with a bloody smile, all of a sudden she instantly went bastard and the building exploded into a fireball of flesh and gore.\n",
      "\n",
      "Bbranded of ending:'02 GF04AdGK4D81G5eP8C5rde459neOps4cB8Dc568392AL\n",
      "\n",
      "2IKFK6vycapkIlV216uWRDe3tHfck_1GaoikDOMrO<|endoftext|>Found my wish suddenly amidst a torrent of sudden, alarming updates Monday morning during the Wachowski School, while school coffee was drying. You have at least noticed me, right now. I'm picnicking with the Caddy full of zombies and goddamn weird face portraits over high school home-trains. This first freak flood has brought this wonderful animal down sharply, murdering many folks's heads as I run, \"outta here…ESE HANG ON CHINA, KARL!!! HER MILF NEEDS TO BE STRONG, KU ON!\" I'm getting stuck at the pedal bullypinder speed, which (after laying around wondering if this guy was weird or if there could be a universe of him) looks like a reaction I should set off.\n",
      "\n",
      "\n",
      "I burst through that speed ritual exit through the back door.\n",
      "\n",
      "\n",
      "Jesse, that obnoxious child Verisign, must still be writhing under the skidmark drink, stuffing a thumb up his pannier like a CHILD. She and Danielle have arrived to alakazam, and indeed this city is in ruins...\n",
      "\n",
      "Can't wait to make that start over from above that second vigor trial thing…\n",
      "\n",
      "\n",
      "The Jett\n",
      "\n",
      "Fuck… he crashed the car and I changed to a bomb machine. Hopefully Torrence Post will be there in a couple of hours to spur me off.\n",
      "\n",
      "Dave, that dude has Einstein inside him… Also, I fully realize that there might be some rope scruples over his restroom every night, as well as the bloody cow in his ass, so he needs some toilet paper at least on hot months ofrdum…. SO late afternoon EST to be getting ready for test.\n",
      "\n",
      "Jake, stay away.\n",
      "\n",
      "…And Dave. Do men exist, after all? Actually, think about it– if it's sports at all. It's the sports that happen in competitive basketball and rugby every day, and…\"Fun\".\n",
      "\n",
      "Done.\n",
      "\n",
      "I'll go in the scream factory:\n",
      "\n",
      "…and night just as a free Jig?\n",
      "\n",
      "He'll must be counting down.\n",
      "\n",
      "Bernie\n",
      "\n",
      "Gary, I have school kicked off this morning, and I am\u001b[0m\n",
      "\u001b[32m2023-03-17 14:42:13.088\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mgenerate_new_tokens\u001b[0m:\u001b[36m121\u001b[0m - \u001b[34m\u001b[1mToken generation took: 10.0405 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python src/model/generate.py gpt --gpt2-config gpt2 --max-new-tokens 1000 --fix-seed --continue-tokens \"My name is Giovanni Giorgio but everybody calls me \" --use-kv-cache"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
